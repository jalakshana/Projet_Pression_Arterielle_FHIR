# Projet_Pression_Arterielle_FHIR

# Surveillance des DonnÃ©es de Pression ArtÃ©rielle avec FHIR et Kafka  

## Introduction  

Ce projet met en place un **systÃ¨me de surveillance des donnÃ©es de pression artÃ©rielle** en **temps rÃ©el** Ã  lâ€™aide de **FHIR (Fast Healthcare Interoperability Resources)** et **Apache Kafka**.  
L'objectif est d'assurer une **collecte, analyse et visualisation efficace** des donnÃ©es de pression artÃ©rielle, en utilisant **Elasticsearch et Kibana** pour dÃ©tecter et suivre les anomalies telles que l'hypertension et l'hypotension.  

## Objectifs  

âœ” **GÃ©nÃ©rer des messages FHIR** contenant les mesures de pression artÃ©rielle.  
âœ” **Transmettre ces messages** via Kafka.  
âœ” **Analyser les donnÃ©es en temps rÃ©el** pour dÃ©tecter les anomalies.  
âœ” **Stocker et indexer les donnÃ©es** dans Elasticsearch.  
âœ” **Visualiser les rÃ©sultats** sur un tableau de bord Kibana.  

## Technologies utilisÃ©es  

**InteropÃ©rabilitÃ© SantÃ©** : FHIR (Fast Healthcare Interoperability Resources)  
**Streaming & Messaging** : Apache Kafka  
**Stockage & Indexation** : Elasticsearch  
**Visualisation** : Kibana  
**Langages** : Python  
**BibliothÃ¨ques** : `fhir.resources`, `kafka-python`, `elasticsearch`, `faker`  
**Orchestration** : Docker & Docker Compose  

## Installation et configuration  

### 1ï¸âƒ£ **Cloner le dÃ©pÃ´t**  
```bash
git clone https://github.com/jalakshana/Projet_Pression_Arterielle_FHIR.git
```
2ï¸âƒ£ **DÃ©marrer lâ€™environnement Docker**
```bash
docker-compose up -d
```
3ï¸âƒ£ **Installer les dÃ©pendances Python**
```bash
pip install -r requirements.txt
```
4ï¸âƒ£ **GÃ©nÃ©rer et publier des messages FHIR**
```bash
python generate_fhir.py
python producer.py
```
5ï¸âƒ£ **Consommer les messages et analyser les donnÃ©es**
```bash
python consumer.py
```
6ï¸âƒ£ **AccÃ©der au Tableau de Bord Kibana**
Ouvrir un navigateur et aller Ã  :
ðŸ”— http://localhost:5601

## Fonctionnement du SystÃ¨me

**GÃ©nÃ©ration des messages FHIR**
* Le script generate_fhir.py crÃ©e des donnÃ©es conformes Ã  la norme FHIR avec des valeurs alÃ©atoires pour la pression systolique et diastolique.
* Les donnÃ©es sont stockÃ©es sous forme de fichiers JSON avant dâ€™Ãªtre envoyÃ©es Ã  Kafka.

**Transmission des donnÃ©es via Kafka**
* producer.py publie les messages sur un topic Kafka appelÃ© blood_pressure_readings.
* Kafka assure la distribution des messages Ã  plusieurs consommateurs.

**Analyse des donnÃ©es et dÃ©tection des anomalies**

consumer.py rÃ©cupÃ¨re les donnÃ©es Kafka et vÃ©rifie les valeurs de pression :
* Hypertension : Systolique > 140 mmHg ou Diastolique > 90 mmHg
* Hypotension : Systolique < 90 mmHg ou Diastolique < 60 mmHg

Les anomalies sont indexÃ©es dans Elasticsearch pour un suivi Ã  long terme.

**Visualisation dans Kibana**
Un dashboard Kibana permet de voir :
* Distribution des pressions artÃ©rielles
* DÃ©tection des anomalies en temps rÃ©el
* Ã‰volution des anomalies sur une pÃ©riode donnÃ©e
